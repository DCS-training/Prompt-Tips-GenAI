{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Prompting Examples\n",
        "\n",
        "Material is mainly coming from the part of short course designed by DeepLearning.ai, offered as [ChatGPT Prompt Engineering for Developers](https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/)\n",
        "\n",
        "Some prompt and text examples are modified with different ingridients!\n",
        "\n",
        "## Setup\n",
        "\n",
        "If you are interested in doing experiments via python, you need to have OpenAI API key for this (not the only choice but material is designed relying on this tool)\n",
        "\n",
        "#### Load the API key and relevant Python libaries."
      ],
      "metadata": {
        "id": "vwgwMEGc18ka"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BJQhur9v13-I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "816c5097-a555-410a-dfa3-c1c8eb1ad4b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m579.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.9.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2023.11.17)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Installing collected packages: openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-0.28.0\n"
          ]
        }
      ],
      "source": [
        "pip install openai==0.28"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "tags": [],
        "id": "6c382975"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import os\n",
        "\n",
        "# from dotenv import load_dotenv, find_dotenv\n",
        "# _ = load_dotenv(find_dotenv())\n",
        "\n",
        "openai.api_key  = os.getenv('OPENAI_API_KEY')\n",
        "\n",
        "# os.environ[\"OPENAI_API_KEY\"] = \"Your OpenAI-API-key\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Main Helper function\n",
        "Throughout this script, you can use OpenAI's `gpt-3.5-turbo` model and the [chat completions endpoint](https://platform.openai.com/docs/guides/chat).\n",
        "\n",
        "This helper function will make it easier to use prompts and look at the generated outputs.  \n",
        "\n"
      ],
      "metadata": {
        "id": "uQo11qUB2rJV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "tags": [],
        "id": "a7dff174"
      },
      "outputs": [],
      "source": [
        "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0, # this is the degree of randomness of the model's output\n",
        "    )\n",
        "    return response.choices[0].message[\"content\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** This and all other lab notebooks of this course use OpenAI library version `0.27.0`.\n",
        "\n",
        "In order to use the OpenAI library version `1.0.0`, here is the code that you would use instead for the `get_completion` function:\n",
        "\n",
        "```python\n",
        "client = openai.OpenAI()\n",
        "\n",
        "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "```"
      ],
      "metadata": {
        "id": "NPC8xGVE3EEM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Main Tactics\n",
        "\n",
        "#### Tactic 1: Use delimiters to clearly indicate distinct parts of the input\n",
        "- Delimiters can be anything like: ```, \"\"\", < >, `<tag> </tag>`, `:`\n",
        "\n",
        "- We are using a backslash \\ to make the text fit on the screen without inserting newline '\\n' characters."
      ],
      "metadata": {
        "id": "bA2uj_Yc3GcF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87121316",
        "outputId": "ad950641-d13d-4fb9-b713-95b4f49b47d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This text discusses the advancements in Generative AI tools, particularly in the field of Natural Language Processing (NLP), and emphasizes the importance of prompt engineering in order to effectively utilize these tools, with a training workshop aimed at researchers and practitioners interested in using Gen-AI tools efficiently and responsibly.\n"
          ]
        }
      ],
      "source": [
        "text = f\"\"\"\n",
        "With the recent advancements in the field of Natural Language Processing (NLP), \\\n",
        "Generative AI (Gen-AI) tools are rapidly evolving and have already become powerful tools \\\n",
        "for various sectors. Including the widely known tool ChatGPT, there are various competitors \\\n",
        "in the market with recently proposed open-source alternatives. Regarding the method under the hood \\\n",
        "and the data set they are trained on, different tools have certain capabilities and limitations.\\\n",
        "\\To have a better conservation with these Gen-AI tools and fully harness their potential, \\\n",
        "it is crucial to be aware of the concept of prompt engineering and power. \\\n",
        "This training workshop aims to introduce the main strategies of prompt engineering including \\\n",
        "tips and certain practices to achieve optimal outputs with Gen-AI tools. After providing a hands-on \\\n",
        "overview of prompt engineering, certain features of ChatGPT will be discussed for fostering \\\n",
        "the research practices. The target audience for this workshop is mainly researchers and practitioners \\\n",
        "working in different fields who are interested in using the Gen-AI tools more \\\n",
        "efficiently and responsibly in their daily work. \\\n",
        "This is a beginner-level workshop. No previous knowledge on the topic is required/expected and the trainer\\\n",
        "will cover the basics of the method. If you want to explore the topic before the workshop \\\n",
        "you can have a look at this Prompt Engineering Guide.\n",
        "\"\"\"\n",
        "prompt = f\"\"\"\n",
        "Summarize the text delimited by triple backticks \\\n",
        "into a single sentence.\n",
        "```{text}```\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tactic 2: Ask for a structured output\n",
        "- JSON, HTML"
      ],
      "metadata": {
        "id": "W0QUKjwt3OI8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b50bbbd",
        "outputId": "17c049d2-2769-4105-a24e-7d0cad72823d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"training_details\": [\n",
            "    {\n",
            "      \"instructor_name\": \"John Smith\",\n",
            "      \"level\": \"Beginner\",\n",
            "      \"material\": \"Introduction to Python book\"\n",
            "    },\n",
            "    {\n",
            "      \"instructor_name\": \"Jane Doe\",\n",
            "      \"level\": \"Intermediate\",\n",
            "      \"material\": \"Python Data Science Handbook\"\n",
            "    },\n",
            "    {\n",
            "      \"instructor_name\": \"Michael Johnson\",\n",
            "      \"level\": \"Advanced\",\n",
            "      \"material\": \"Deep Learning with Python\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "{\n",
            "  \"instructor_name\": \"Ozan Evkaya\",\n",
            "  \"level\": \"Beginner\",\n",
            "  \"material\": \"Prompt Engineering Guide\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "text = f\"\"\"\n",
        "This is a beginner-level workshop. \\\n",
        "No previous knowledge on the topic is required/expected and the trainer \\\n",
        "will cover the basics of the method. If you want to explore the topic \\\n",
        "before the workshop you can have a look at this Prompt Engineering Guide. \\\n",
        "This workshop will be taught by Ozan Evkaya.\n",
        "\"\"\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Generate a list of training details from the given text delimited by triple backticks as instructor, level of workshop and suggested material\n",
        "Provide them in JSON format with the following keys:\n",
        "instructor_name, level, material.\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Generate a list of training details from the given ```{text}``` delimited by triple backticks as instructor, level of workshop and suggested material\n",
        "Provide them in JSON format with the following keys:\n",
        "instructor_name, level, material.\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22a71c4f-b1f1-4d67-ad5a-e49fc1e3147d"
      },
      "source": [
        "#### Tactic 3: Ask the model to check whether conditions are satisfied"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "tags": [],
        "id": "f0ae612e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "040d0626-55a7-4f28-99d2-fd87cbe4d293"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion for Text 1:\n",
            "Step 1 - Get some water boiling.\n",
            "Step 2 - Grab a cup and put a tea bag in it.\n",
            "Step 3 - Pour the hot water over the tea bag.\n",
            "Step 4 - Let the tea steep for a few minutes.\n",
            "Step 5 - Take out the tea bag.\n",
            "Step 6 - Add sugar or milk to taste.\n",
            "Step 7 - Enjoy your cup of tea.\n"
          ]
        }
      ],
      "source": [
        "text_1 = f\"\"\"\n",
        "Making a cup of tea is easy! First, you need to get some \\\n",
        "water boiling. While that's happening, \\\n",
        "grab a cup and put a tea bag in it. Once the water is \\\n",
        "hot enough, just pour it over the tea bag. \\\n",
        "Let it sit for a bit so the tea can steep. After a \\\n",
        "few minutes, take out the tea bag. If you \\\n",
        "like, you can add some sugar or milk to taste. \\\n",
        "And that's it! You've got yourself a delicious \\\n",
        "cup of tea to enjoy.\n",
        "\"\"\"\n",
        "prompt = f\"\"\"\n",
        "You will be provided with text delimited by triple quotes.\n",
        "If it contains a sequence of instructions, \\\n",
        "re-write those instructions in the following format:\n",
        "\n",
        "Step 1 - ...\n",
        "Step 2 - …\n",
        "…\n",
        "Step N - …\n",
        "\n",
        "If the text does not contain a sequence of instructions, \\\n",
        "then simply write \\\"No steps provided.\\\"\n",
        "\n",
        "\\\"\\\"\\\"{text_1}\\\"\\\"\\\"\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(\"Completion for Text 1:\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3c5866b8-d8c7-4e19-93db-401315f64954"
      },
      "source": [
        "#### Tactic 4: \"Few-shot\" prompting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "tags": [],
        "id": "82ce1540",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c40c43cd-9686-405b-a7b9-792d30bc5e75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<assistant>: ChatGPT is a specific large language model developed by OpenAI. It is designed to generate human-like responses in a conversational manner. It has been trained on a wide range of internet text to learn patterns and generate coherent and contextually relevant responses. ChatGPT has been fine-tuned to be more useful and safe for various applications.\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Your task is to answer in a consistent style.\n",
        "\n",
        "<tutor>: Teach me about Large Language Models.\n",
        "\n",
        "<student>: Large language models (LLM) are very large deep learning models \\\n",
        "that are pre-trained on vast amounts of data. \\\n",
        "The underlying transformer is a set of neural networks that \\\n",
        "consist of an encoder and a decoder with self-attention capabilities.\n",
        "\n",
        "<child>: Teach me about ChatGPT.\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ece7a8ee-1a2d-415d-8c10-500ecff24b10"
      },
      "source": [
        "### Principle 2: Give the model time to “think”\n",
        "\n",
        "#### Tactic 1: Specify the steps required to complete a task\n",
        "\n",
        "Given text below is the abstract of the paper entitled\n",
        "[Multimodal Large Language Models: A Survey](https://arxiv.org/abs/2311.13165)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e7d6860",
        "outputId": "952ca665-719a-4491-9ef8-0f56b50013ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completion for prompt 1:\n",
            "The exploration of multimodal language models integrates multiple data types, such as images, text, language, audio, and other heterogeneity, to enable a more comprehensive understanding of diverse data, and this paper provides a practical guide, insights into technical aspects, a compilation of algorithms and datasets, and explores the applications and challenges of multimodal models. \n",
            "\n",
            "L'esplorazione dei modelli di linguaggio multimodali integra diversi tipi di dati, come immagini, testo, linguaggio, audio e altre eterogeneità, per consentire una comprensione più completa dei dati diversi, e questo articolo fornisce una guida pratica, approfondimenti sugli aspetti tecnici, una raccolta di algoritmi e dataset, ed esplora le applicazioni e le sfide dei modelli multimodali. \n",
            "\n",
            "{\n",
            "  \"summary\": \"The exploration of multimodal language models integrates multiple data types, such as images, text, language, audio, and other heterogeneity, to enable a more comprehensive understanding of diverse data, and this paper provides a practical guide, insights into technical aspects, a compilation of algorithms and datasets, and explores the applications and challenges of multimodal models.\",\n",
            "  \"italian_summary\": \"L'esplorazione dei modelli di linguaggio multimodali integra diversi tipi di dati, come immagini, testo, linguaggio, audio e altre eterogeneità, per consentire una comprensione più completa dei dati diversi, e questo articolo fornisce una guida pratica, approfondimenti sugli aspetti tecnici, una raccolta di algoritmi e dataset, ed esplora le applicazioni e le sfide dei modelli multimodali.\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "text = f\"\"\"\n",
        "The exploration of multimodal language models integrates multiple data types, \\\n",
        "such as images, text, language, audio, and other heterogeneity. \\\n",
        "While the latest large language models excel in text-based tasks, \\\n",
        "they often struggle to understand and process other data types. \\\n",
        "Multimodal models address this limitation by combining various modalities, \\\n",
        "enabling a more comprehensive understanding of diverse data. This paper begins \\\n",
        "by defining the concept of multimodal and examining the historical development of \\\n",
        "multimodal algorithms. Furthermore, we introduce a range of multimodal products, \\\n",
        "focusing on the efforts of major technology companies. A practical guide is provided, \\\n",
        "offering insights into the technical aspects of multimodal models. Moreover, we present a \\\n",
        "compilation of the latest algorithms and commonly used datasets, providing researchers \\\n",
        "with valuable resources for experimentation and evaluation. Lastly, we explore the \\\n",
        "applications of multimodal models and discuss the challenges associated with their development. \\\n",
        "By addressing these aspects, this paper aims to facilitate a deeper understanding of multimodal \\\n",
        "models and their potential in various domains.\n",
        "\"\"\"\n",
        "# example 1\n",
        "prompt_1 = f\"\"\"\n",
        "Perform the following actions:\n",
        "1 - Summarize the following text delimited by triple \\\n",
        "backticks with 1 sentence.\n",
        "2 - Translate the summary into Italian.\n",
        "3 - Output a json object that contains the following \\\n",
        "keys: summary, italian_summary\n",
        "\n",
        "Separate your answers with line breaks.\n",
        "\n",
        "Text:\n",
        "```{text}```\n",
        "\"\"\"\n",
        "response = get_completion(prompt_1)\n",
        "print(\"Completion for prompt 1:\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fec80fdb-92db-48f6-8f1d-b03c26385bad"
      },
      "source": [
        "#### Tactic 2: Instruct the model to work out its own solution before rushing to a conclusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "tags": [],
        "id": "ff5cc985",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "589e9a71-436d-44e3-ac54-bcefe2b40e09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The student's solution is correct. The total cost for the first year of operations is indeed 450x + 100,000.\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Determine if the student's solution is correct or not.\n",
        "\n",
        "Question:\n",
        "I'm building a solar power installation and I need \\\n",
        " help working out the financials.\n",
        "- Land costs $100 / square foot\n",
        "- I can buy solar panels for $250 / square foot\n",
        "- I negotiated a contract for maintenance that will cost \\\n",
        "me a flat $100k per year, and an additional $10 / square \\\n",
        "foot\n",
        "What is the total cost for the first year of operations\n",
        "as a function of the number of square feet.\n",
        "\n",
        "Student's Solution:\n",
        "Let x be the size of the installation in square feet.\n",
        "Costs:\n",
        "1. Land cost: 100x\n",
        "2. Solar panel cost: 250x\n",
        "3. Maintenance cost: 100,000 + 100x\n",
        "Total cost: 100x + 250x + 100,000 + 100x = 450x + 100,000\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f322ebd9-0f8a-43aa-97fe-5eac70cdcc6a"
      },
      "source": [
        "#### Note that the student's solution is actually not correct.\n",
        "#### We can fix this by instructing the model to work out its own solution first."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "tags": [],
        "id": "703f7003",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8c90282-00ef-4656-8b67-b881addb0175"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To calculate the total cost for the first year of operations, we need to add up the costs of land, solar panels, and maintenance.\n",
            "\n",
            "1. Land cost: $100 / square foot\n",
            "2. Solar panel cost: $250 / square foot\n",
            "3. Maintenance cost: $100,000 (flat fee) + $10 / square foot\n",
            "\n",
            "Let x be the size of the installation in square feet.\n",
            "\n",
            "1. Land cost: 100 * x\n",
            "2. Solar panel cost: 250 * x\n",
            "3. Maintenance cost: 100,000 + 10 * x\n",
            "\n",
            "Total cost: 100 * x + 250 * x + 100,000 + 10 * x = 350 * x + 100,000\n",
            "\n",
            "Is the student's solution the same as the actual solution just calculated:\n",
            "No\n",
            "\n",
            "Student grade:\n",
            "Incorrect\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Your task is to determine if the student's solution \\\n",
        "is correct or not.\n",
        "To solve the problem do the following:\n",
        "- First, work out your own solution to the problem including the final total.\n",
        "- Then compare your solution to the student's solution \\\n",
        "and evaluate if the student's solution is correct or not.\n",
        "Don't decide if the student's solution is correct until\n",
        "you have done the problem yourself.\n",
        "\n",
        "Use the following format:\n",
        "Question:\n",
        "```\n",
        "question here\n",
        "```\n",
        "Student's solution:\n",
        "```\n",
        "student's solution here\n",
        "```\n",
        "Actual solution:\n",
        "```\n",
        "steps to work out the solution and your solution here\n",
        "```\n",
        "Is the student's solution the same as actual solution \\\n",
        "just calculated:\n",
        "```\n",
        "yes or no\n",
        "```\n",
        "Student grade:\n",
        "```\n",
        "correct or incorrect\n",
        "```\n",
        "\n",
        "Question:\n",
        "```\n",
        "I'm building a solar power installation and I need help \\\n",
        "working out the financials.\n",
        "- Land costs $100 / square foot\n",
        "- I can buy solar panels for $250 / square foot\n",
        "- I negotiated a contract for maintenance that will cost \\\n",
        "me a flat $100k per year, and an additional $10 / square \\\n",
        "foot\n",
        "What is the total cost for the first year of operations \\\n",
        "as a function of the number of square feet.\n",
        "```\n",
        "Student's solution:\n",
        "```\n",
        "Let x be the size of the installation in square feet.\n",
        "Costs:\n",
        "1. Land cost: 100x\n",
        "2. Solar panel cost: 250x\n",
        "3. Maintenance cost: 100,000 + 100x\n",
        "Total cost: 100x + 250x + 100,000 + 100x = 450x + 100,000\n",
        "```\n",
        "Actual solution:\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summarize with a word/sentence/character limit"
      ],
      "metadata": {
        "id": "huXmw1pDXgsk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "show_review = \"\"\"\n",
        "Welcome to Duffy and Elf Lyons' bank heist. \\\n",
        "A hysterically funny physical show with Visual Vernacular (VV), \\\n",
        "conducted in British Sign Language with some very violent live sound foley. \\\n",
        "Duffy and Elf are friends. Duffy signs, Elf doesn’t. Elf speaks, Duffy doesn’t. \\\n",
        "Let’s see how this works out… This is a comedy show. This is a bank heist. \\\n",
        "This is a love story. You've never seen anything like it. \\\n",
        "Created by award-winning performers Duffy and Elf Lyons. \\\n",
        "'Praise her genius – and go' ***** (Telegraph).\\\n",
        "Edinburgh Comedy Award Best Show nominee.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "PimEHhKgXjG8"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Your task is to generate a short summary of a show description \\\n",
        "shared by Fringe website to give feedback to the \\\n",
        "interested audience.\n",
        "\n",
        "Summarize the description below, delimited by triple\n",
        "backticks, in at most 30 words, and focusing on any aspects \\\n",
        "that mention the unique part of the show.\n",
        "\n",
        "Review: ```{show_review}```\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZpD5pLUX6L0",
        "outputId": "2ef2a22d-bc7d-4f98-e9a4-1b71591c32ae"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary: A unique comedy show featuring a bank heist, combining British Sign Language and live sound foley, with a love story twist. Unprecedented and praised by critics.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sentiment (positive/negative)\n",
        "\n",
        "One of the classical tasks of the field of NLP"
      ],
      "metadata": {
        "id": "GiXMK5JZZodf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lamp_review = \"\"\"\n",
        "Needed a nice lamp for my bedroom, and this one had \\\n",
        "additional storage and not too high of a price point. \\\n",
        "Got it fast.  The string to our lamp broke during the \\\n",
        "transit and the company happily sent over a new one. \\\n",
        "Came within a few days as well. It was easy to put \\\n",
        "together.  I had a missing part, so I contacted their \\\n",
        "support and they very quickly got me the missing piece! \\\n",
        "Lumina seems to me to be a great company that cares \\\n",
        "about their customers and products!!\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "5n7BrqOXZoDN"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Identify a list of emotions that the writer of the \\\n",
        "following review is expressing. Include no more than \\\n",
        "five items in the list. Format your answer as a list of \\\n",
        "lower-case words separated by commas.\n",
        "\n",
        "Review text: '''{lamp_review}'''\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2f7D4xcaXFF",
        "outputId": "77238981-e14a-45fa-c6a8-94361e04fb41"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "satisfied, pleased, grateful, impressed, happy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Identify the following items from the review text:\n",
        "- Item purchased by reviewer\n",
        "- Company that made the item\n",
        "\n",
        "The review is delimited with triple backticks. \\\n",
        "Format your response as a JSON object with \\\n",
        "\"Item\" and \"Brand\" as the keys.\n",
        "If the information isn't present, use \"unknown\" \\\n",
        "as the value.\n",
        "Make your response as short as possible.\n",
        "\n",
        "Review text: '''{lamp_review}'''\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nndzj7DOaczc",
        "outputId": "8cca8572-0f20-421c-b6be-f1691e9351c7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"Item\": \"lamp\",\n",
            "  \"Brand\": \"Lumina\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Translation\n",
        "\n",
        "ChatGPT is trained with sources in many languages. This gives the model the ability to do translation. Here are some examples of how to use this capability."
      ],
      "metadata": {
        "id": "e3NQcS6VbDDR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Translate the following English text to Italian: \\\n",
        "```Hi, I would like to share some experiences about Generative AI```\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IgImq-GwbDVZ",
        "outputId": "02347ed6-8ffe-4c12-a4eb-ad98d0249b0e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ciao, mi piacerebbe condividere alcune esperienze riguardo all'IA generativa.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tone Transformation\n",
        "Writing can vary based on the intended audience. ChatGPT can produce different tones."
      ],
      "metadata": {
        "id": "rOkFnWvNbVH2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Translate the following from formal to a casual response:\n",
        "'I regret to inform you that you are not short listed for that specific position'\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpMBn2WSbL0q",
        "outputId": "bce2c80f-7bf3-4fd1-8db3-fe138398dfea"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'm sorry, but you didn't make the cut for that job.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Other examples might be (not limited to);\n",
        "\n",
        "- Format Conversion\n",
        "\n",
        "- Spellcheck/Grammar check."
      ],
      "metadata": {
        "id": "Vbu75wZpblXO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "HFlCfK71c2Tu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# given the sentiment from the review\n",
        "# and the original customer message, customize the email\n",
        "sentiment = \"positive\"\n",
        "\n",
        "# review for a blender\n",
        "review = f\"\"\"\n",
        "Elf and Duffy work so well onstage together. \\\n",
        "They’re both amazing physical comedians and I laughed so so much. \\\n",
        "Kudos to their interpreter as well! Go see this show!\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "O74KkSGEbv8A"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "You are a Fringe customer service AI assistant.\n",
        "Your task is to send an email reply to a valued audience.\n",
        "Given the audience email delimited by ```, \\\n",
        "Generate a reply to thank the audience for their review.\n",
        "If the sentiment is positive or neutral, thank them for \\\n",
        "their review.\n",
        "If the sentiment is negative, apologize and suggest that \\\n",
        "they can reach out to Fringe audience service.\n",
        "Make sure to use specific details from the review.\n",
        "Write in a concise and professional tone.\n",
        "Sign the email as `AI customer agent`.\n",
        "Customer review: ```{review}```\n",
        "Review sentiment: {sentiment}\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqKyzkk1c6tr",
        "outputId": "fff21db4-c275-4e50-8749-194729da05e6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dear valued audience,\n",
            "\n",
            "Thank you for taking the time to share your review with us. We greatly appreciate your kind words and are thrilled to hear that you enjoyed the performance of Elf and Duffy. We agree that they are both amazing physical comedians and it's wonderful to know that you laughed so much during the show. We will make sure to pass on your kudos to their interpreter as well.\n",
            "\n",
            "We are delighted that you had such a positive experience and we hope to welcome you back to Fringe soon. If you have any further feedback or if there's anything else we can assist you with, please don't hesitate to reach out to our audience service team.\n",
            "\n",
            "Thank you once again for your support and for being a valued audience member.\n",
            "\n",
            "Best regards,\n",
            "\n",
            "AI customer agent\n"
          ]
        }
      ]
    }
  ]
}